\chapter{A Metodologia Proposta}\label{chap_methodology}

Neste capítulo, a metodologia proposta para sintetizar controlodores digitais com realimentação de estados, considerando fragilidade e especificações de desempenho será completamente descrita. Primeiramente, mostraremos as metodologias formalizadas para verificar sistemas de controle digital, com respeito a especificações de performance, no caso máximo tempo de assentamento e máximo sobressinal. A formalização utilizada para estimar o máximo sobressinal, bem como a invariante formalizada para verificar o máximo tempo de assentamento. Também são descritos os algoritmos criados para fazer a devida verificação das mesmas. Finalmente, a descrição completa da técnica que utilizamos para realizar o processo de síntese.

\section{Visão Geral do Método}
\label{sec:method-overview}

Aqui, o método proposto é descrito brevemente, como mostrado na Figura~\ref{figure:methodology}, e uma explicação mais detalhada é exposta nas seções seguitnes. Dado um programa concorrente $P$, primeiramente checa-se se ele apresenta uma execução mal-sucedida com relação a uma determinada intercalação. Para realizar tal tarefa, $P$ é executado em um verificador de modelos duas vezes: a primeira execução verifica se existe algum bloqueio fatal e a segunda é responsável por outros tipos de violação, tais como erros de aquisição de semáforo, divisão por zero, segurança de ponteiros, estouro aritmético e violação de limites de vetores. Não é possível verificá-lo apenas uma vez porque os verificadores de modelos separam essas verificações, \textit{i.e.}, é necessário adicionar uma opção de linha de comando para habilitar a detecção de bloqueios fatais e ignorar violações devido a assertivas. Caso um contraexemplo possa ser obtido nesse passo, é possível prosseguir com o método. Então, o próximo passo define as regras de transformação, que são as instruções sequenciais que substituirão as originais concorrentes, e um arcabouço sequencial, o qual tem como objetivo simular a execução concorrente da intercalação mal-sucedida. O terceiro passo consiste em usar o método proposto por Griesmayer~\cite{Griesmayer:2007} para instrumentar atribuições e expressões, de forma a apontar locais e instruções defeituosas do programa. Tal programa instrumentado pode então ser executado, usando um verificador de modelos, e é possível coletar as linhas defeituosas, até que a verificação associada não produza diferentes elementos. Essa iteração é descrita na Figura~\ref{figure:methodology} por meio dos passos $3$, $4$, já que o método busca novos contraexemplos, com o intuito de encontrar novas linhas defeituosas. Finalmente, as linhas defeituosas são obtidas, assim como atribuições necessárias para produzir uma execução bem-sucedida de $P$.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/methodology}
  \caption{Metodologia proposta.}
  \label{figure:methodology}
\end{figure}

%-------------------------------------------------------------------
\section{Verifying Non-fragile Performance Specification Requirements}
\label{sec:verification}
%-------------------------------------------------------------------

As we described, in this work we use a variation of CEGIS synthesis to synthesize a controller in order to satisfy performance requirements in digital control systems such as settling-time and maximum overshoot. In CEGIS strategy of we have basically two main stages: synthesis and verification. In this section we show the verification method of settling-time and maximum overshoot of digital control systems.
%--------------------------------------------------------------------------------
\subsection{Maximum Overshooting Estimation}
\label{sec:modformver}
%--------------------------------------------------------------------------------

Algorithm~\ref{alg:overshootEst} describes a procedure for estimating $y_{\mathrm{p}}$ (maximum peak value in a system's response) and $k_{\mathrm{p}}$ (sample where $y_{\mathrm{p}}$ is located), in order to find a formal approach to verify the maximum overshoot used in our CEGIS approach.

%\begin{algorithm}
%    \caption{Estimation of $y_{\mathrm{p}}$ and $k_{\mathrm{p}}$}
%    \label{alg:overshootEst}
%    \begin{algorithmic}[1] % The number tells where the line numbering should start
%        \Procedure{estimate\_maxPeak\_value}{$   $}
%          \State $y_\mathrm{p} \gets y(k)$
%          \State $lastGrad \gets 1$
%          \Loop
%            \If {$|y(k+1)|>|y(k)|$}
%              \State $gradient = (gradient>0)?(gradient+1):1$
%              \If {$|y(k+1)| != |y(k)|$}
%                \State $firstGradSample = y(k+1)$
%                \State $firstGradSampleIdx = k+1$
%              \EndIf
%            \Else
%              \State $gradient = (gradient<0)?(gradient-1):-1$
%            \EndIf
%            \If {$(lastGrad>0) ~and~ (gradient < 0)$}
%              \If {$|firstGradSample| <= |k_\mathrm{p}|$}
%                \State increment $numBadPeaks$
%                \If {$numBadPeaks > 2$}
%                  \State $exit(\textbf{loop})$
%                \Else
%                  \State $y_\mathrm{p} = firstGradSample$
%                  \State $k_\mathrm{p} = firstGradSampleIdx$
%                \EndIf
%              \ElsIf {$(grad > 10) ~and~ (|(y(k+1)-yss)/yss| < 0.001)$}
%                \If {$|yss|>|y_\mathrm{p}|$}
%                  \State $y_\mathrm{p} = yss$
%                  \State $k_\mathrm{p} = 0$
%                \EndIf
%                \State $exit(\textbf{loop})$
%              \EndIf
%            \EndIf
%            \State $lastGrad = grad$
%            \State increment $k$
%          \EndLoop
%        \EndProcedure
%    \end{algorithmic}
%\end{algorithm}

\begin{algorithm}[H]
  \renewcommand{\algorithmcfname}{Algorítmo}%
  \SetAlgoLined
  \KwPr{}
  $y_\mathrm{p} \gets y(k)$
  $lastGrad \gets 1$
  \Eq{infinito}{
  \eSe{$|y(k+1)|>|y(k)|$}{
     $gradient = (gradient>0)?(gradient+1):1$\;
     \Se{$|y(k+1)| != |y(k)|$}{
      $firstGradSample = y(k+1)$\;
      $firstGradSampleIdx = k+1$\;
    }
  }{
    $gradient = (gradient<0)?(gradient-1):-1$\;
  }
  \Se{$(lastGrad>0) ~and~ (gradient < 0)$}{
     \eSe{$|firstGradSample| <= |k_\mathrm{p}|$}{
       increment $numBadPeaks$\;
       \eSe{$numBadPeaks > 2$}{
         $exit(\textbf{loop})$\;
       }{
         $y_\mathrm{p} = firstGradSample$\;
         $k_\mathrm{p} = firstGradSampleIdx$\;
       }
     }\SenãoSe{$(grad > 10) ~and~ (|(y(k+1)-yss)/yss| < 0.001)$}{
       \eSe{$|yss|>|y_\mathrm{p}|$}{
         $y_\mathrm{p} = yss$\;
         $k_\mathrm{p} = 0$\;
       }{
         $exit(\textbf{loop})$\;
       }
     }
  }
  $lastGrad = grad$\;
  increment $k$\;
  }
  \caption{Estimation of $y_{\mathrm{p}}$ and $k_{\mathrm{p}}$}\label{alg:overshootEst}
\end{algorithm}

The procedure basically looks for the maximum peak value in the output response of a system, using the concept of gradient to check if there is a peak. We start at the first sample of the output system, and compare the next samples, and then we proceed to find the largest peak (with the same sign of $y_\mathrm{ss}$) which is our maximum peak value $y_p$.


%--------------------------------------------------------------------------------
\subsection{Maximum Settling-Time Invariant Estimation}
\label{sec:modformver}
%--------------------------------------------------------------------------------

In this study, we aim to check whether a given digital control system meets a required settling-time and, as a consequence, we need to model its behavior. In addition, we use $\hat{k}$ as an invariant for settling-time verification. A mapping $\phi$ of a given collection $M$ of mathematical objects endowed with a fixed equivalence relation $\rho$, into another collection $N$ of mathematical objects, that is constant on the equivalence classes of $M$, with respect to $\rho$ (more precisely, that is an invariant of the equivalence relation $\rho$ on $M$). If $X$ is an object in $M$, then one can often says that $\phi(M)$ is an invariant of the object $X$~\cite{springer2006invariant}. In other words, once we calculate $\hat{k}$, it will remain unchanged. 

In that sense, let $S_1=\{|\lambda_{\mathrm{1}}|,|\lambda_{\mathrm{2}}|,\dots,|\lambda_n|\}$ be the set of absolute values of eigenvalues \cite{chen1995linear} of system $\Omega$ and $\overline{\lambda}=\max(S_{\mathrm{1}})$. We can now define a heuristic function that represents the output response of $\bar{\Omega}$ as
\begin{equation}\label{eq:saidaNova}
\overline{y}(k)=y_{\mathrm{ss}}+\overline{c}\overline{\lambda}^{k}~,
\end{equation}

\noindent where $\overline{c}$ is a constant that makes $\overline{y}(k)$ enter the settling-time region. Indeed, the heuristic function above uses the slowest eigenvalue $\bar{\lambda}$, ensuring that $\bar{\Omega}$ always reaches the settling-time region after $\Omega$.

In summary, we can find a heuristic function based on the largest eigenvalue of $\Omega$ and then check the moment it enters a settling-time region, because if that happens before the required settling-time, that is also true for $\Omega$.

In order to verify the settling-time of a system, we indicate a settling-time region as a percentage $p$, usually between $0\%$ and $5\%$~\cite{dorf2011modern}, so its upper and lower limits are,

\begin{equation}\label{eq:lupp}
L_{\mathrm{upp}}=\left(1+\frac{p}{100}\right) y_{\mathrm{ss}}
\end{equation}

\noindent and
\begin{equation}
L_{\mathrm{low}}=\left(1-\frac{p}{100}\right) y_{\mathrm{ss}},
\end{equation}

\noindent respectively. The instant (${\hat{k}}$) when a system enters its settling-time region can be found by simply making Eq.~\eqref{eq:saidaNova} equal to Eq.~\eqref{eq:lupp}, due to the form of the curve in Eq.~\eqref{eq:saidaNova}, as follows:
\begin{center}
\begin{equation*}
\begin{aligned}
\left( 1+\frac{p}{100}\right) y_{\mathrm{ss}}=y_{\mathrm{ss}}+\overline{c}\overline{\lambda}^{\hat{k}}\\
y_{\mathrm{ss}}+\frac{p}{100}y_{\mathrm{ss}}=y_{\mathrm{ss}}+\overline{c}\overline{\lambda}^{\hat{k}} \\
\overline{c}\overline{\lambda}^{\hat{k}}=\frac{p}{100}y_{\mathrm{ss}} \\
\log_{\overline{\lambda}} \overline{\lambda}^{\hat{k}}=\log_{\overline{\lambda}}\left( \frac{p}{100\overline{c}}y_{\mathrm{ss}}\right)
\end{aligned}
\end{equation*}

\begin{equation}\label{eq:kbar}
\begin{aligned}
{\hat{k}}=\ceil{  \log_{\overline{\lambda}}\left( \frac{p}{100\overline{c}}y_{\mathrm{ss}}\right)}.
\end{aligned}
\end{equation}
\end{center}

The largest peak of the output system $y_p$ can be obtained for computing $\overline{c}$ and, as a consequence, with Eq.~\eqref{eq:saidaNova}, we make

\begin{equation}\label{eq:cbar}
\begin{aligned}
y_{\mathrm{p}}=&~y_{\mathrm{ss}}+\bar{c}{\bar{\lambda}}^{k_{\mathrm{p}}} \\
\bar{c}=&~\frac{y_{\mathrm{p}}-y_{\mathrm{ss}}}{{\bar{\lambda}}^{k_{\mathrm{p}}}}.
\end{aligned}
\end{equation}

\noindent $y_{\mathrm{p}}$ can be obtained by checking a system's output, in order to find the largest absolute value with the same sign of $y_{\mathrm{ss}}$, and $k_{\mathrm{p}}$ is the sample where $y_{\mathrm{p}}$ is located. 

\subsection{Overshoot Verification Algorithm}
\label{subsec:overshootAlg}

In this section, we explain our overshoot verification technique, which consists in checking if the required percentage overshoot is under or equal to the actual percentage overshoot (calculated).

The maximum overshoot ($M_{\mathrm{p}}$) is the maximum transient value that exceeds $y_{\mathrm{ss}}$. In order to find the overshoot percentage, we perform the following computation:

\begin{equation}
\begin{aligned}
M_{\mathrm{p}} =&~ y_{\mathrm{p}}-y_{\mathrm{ss}} \\
PO =&~ 100\times\frac{M_{\mathrm{p}}}{y_{\mathrm{ss}}},
\end{aligned}
\label{eq:perc_overshoot}
\end{equation}
\noindent  where $y_{\mathrm{p}}$ can be obtained from Algorithm~\ref{alg:overshootEst}.

Figure~\ref{fig:overshootDiag} shows the proposed overshoot verification methodology, which was implemented in DSVerifier. Firstly, a
control system's model (\texttt{Step 1}) is determined and then a controller is designed, for closed-loop (\texttt{Step 2}). After that, the FWL implementation (\texttt{Step 3}) and the required overshoot to be verified (\texttt{Step 4}) are defined, which are then used for creating file \texttt{SpecsFile.ss}. Next, system's stability is checked and if it is stable, the overshoot specification is evaluated.
  
\begin{figure}[H]
\begin{center}
\includegraphics[trim={0.0cm 0.0cm 0.0cm 0cm}, clip,width=0.5\textwidth]{figures/ArchOverShooting.eps}
\caption{Overshoot verification.} 
\label{fig:overshootDiag}
\end{center}
\end{figure}

Overshoot verification consists basically in checking if the computed percentage overshoot $P.O.$ (Eq.~\ref{eq:perc_overshoot}) is less than the required percentage overshoot ($P.O._{\mathrm{r}}$). If that is the case, it returns \texttt{Verification SUCCESSFUL}; otherwise, \texttt{Verification FAILED} is output, as illustrated in Algorithm~\ref{alg:overshootReal}.

%\begin{algorithm}[H]
%\caption{Verify Overshoot }
%\label{alg:overshootReal}
%\begin{algorithmic}[1]
%\Procedure{checkOvershoot($y_{\mathrm{ss}}$, $PO_{\mathrm{r}}$)}{}
%
%    \State $y_{\mathrm{p}} \gets estimate\_maxPeak\_value() $
%    \State $PO \gets \frac{y_{\mathrm{p}}-y_{\mathrm{ss}}}{y_{\mathrm{ss}}}$
%
%    \If {$PO > PO_{\mathrm{r}}$}
%  
%      \State \textbf{return} Verification Failed
%        
%    \EndIf
%
%\State \textbf{return} Verification Successful
%
%\EndProcedure
%\end{algorithmic}
%\end{algorithm}

\begin{algorithm}[H]
  \renewcommand{\algorithmcfname}{Algorítmo}%
  \SetAlgoLined
%  \KwPr{}
  \KwData{$y_{\mathrm{ss}}$, $PO_{\mathrm{r}}$}
%  \KwRes{how to write algorithm with \LaTeX2e }
  $y_{\mathrm{p}} \gets estimate\_maxPeak\_value() $\;
  $PO \gets \frac{y_{\mathrm{p}}-y_{\mathrm{ss}}}{y_{\mathrm{ss}}}$\;
  \eSe{$PO > PO_{\mathrm{r}}$}{
     Verification Failed\;
  }{
  Verification Successful\;
  }
  \caption{Verify Overshoot}\label{alg:overshootReal}
\end{algorithm}


\subsection{Settling-Time Verification Algorithm}
\label{subsec:settime-alg}

In this section, we show our algorithm for settling-time verification, where we use the invariant $\hat{k}$ (see section \ref{sec:modformver}). Our methodology, which is illustrated in Figure \ref{fig:diag1}, provides settling-time verification in open- and closed-loop systems; however, the former do not present controllers and, consequently, FWL effects are not taken into account for it. Its first step consists in obtaining the necessary input parameters, {\it i.e.}, state-space matrices $A$, $B$, $C$, and $D$ and a system's input $u$, which is followed by digital controller design, if a close-loop system is considered (\texttt{Step 2}). Then, the required settling-time $t_{\mathrm{sr}}$, the percentage $p$ of the settling-time region, and the sampling time $T_\mathrm{s}$ are defined (\texttt{Step 4}), which is followed by an FWL implementation, when in closed-loop (\texttt{Step 3}). After that, steps \texttt{A} to \texttt{E} are executed, {\it i.e.}, computation of FWL controller, if closed-loop is chosen (\texttt{Step A}), and steady-state value ($y_{\mathrm{ss}}$), as described in Eq.~\eqref{eq:yss2} (\texttt{Step B}), estimation of the largest peak-values of the system's output ($y_{\mathrm{p}}$) and sample $k_{\mathrm{p}}$ where $y_{\mathrm{p}}$ is located (\texttt{Step C}), and, finally, computation of $\overline{\lambda}$ (\texttt{Step D}), $\overline{c}$ and $\hat{k}$ (\texttt{Step E}).

%\begin{algorithm}
%    \caption{Procedure to find the instant $k_\mathrm{r}$}
%    \label{alg:kreach}
%    \begin{algorithmic}[1] % The number tells where the line numbering should start
%        \Procedure{}{}
%          \While {$y(k) \not\subset \Pi$}
%            \State increment $k$
%          \EndWhile
%          \State $k_\mathrm{r} \gets k$
%        \EndProcedure
%    \end{algorithmic}
%\end{algorithm}

\begin{algorithm}[H]
  \renewcommand{\algorithmcfname}{Algorítmo}%
  \SetAlgoLined
  \Eq{$y(k) \not\subset \Pi$}{
    incrementar $k$\;
  }
  $k_\mathrm{r} \gets k$\;
  \caption{Procedimento para encontrar o instante $k_\mathrm{r}$}\label{alg:kreach}
\end{algorithm}


\begin{figure*}[ht]
\begin{center}
\includegraphics[trim={0.0cm 0.0cm 0.0cm 0cm}, clip,width=0.7\textwidth]{figures/Archstever.eps}
\caption{The proposed settling-time verification methodology.} 
\label{fig:diag1}
\end{center}
\end{figure*}


The proposed procedure for verifying settling-times, which is described in Algorithm~\ref{alg:settlingtime}, consists in first checking if $\hat{k}$, which was previously computed and used as parameter, is lower than the required settling-time $k_{\mathrm{sr}}=\frac{t_{\mathrm{sr}}}{T_\mathrm{s}}$, which can also be checked through $\hat{k} \times T_{\mathrm{s}} \leq t_{\mathrm{sr}}$ (as used in Algorithm~\ref{alg:settlingtime}). If that is the case, we can assure that the output signal is within $\Pi$ (see Section \ref{sec:modformver}) after $t_{\mathrm{sr}}$ and, as a consequence, the associated verification is already successful; otherwise, we still need to check if $y$ remains within $\Pi$ from $k_{\mathrm{sr}}$ to $\hat{k}$ and, if the latter is not true for any sample $y$, the resulting verification fails. 


%\begin{algorithm}[H]
%\caption{Verify Settling Time }
%\label{alg:settlingtime}
%\begin{algorithmic}[1]
%\Procedure{checkSettlingTime(%$\hat{k}$, $t_{\mathrm{sr}}$, $T_{\mathrm{s}}$, $L_{\mathrm{low}}$, $L_{\mathrm{upp}}$
%)}{}
%
%  \If {$y_\mathrm{p} \subset \Pi$}
%    \State {$\hat{k} \gets k_\mathrm{r}$}
%  %\EndIf
%  
%  \Else
%
%    \State $k \gets \frac{t_{\mathrm{sr}}}{T_{\mathrm{s}}}$
%    \If {$k > \hat{k}$}
%      \State \textbf{return} Verification Successful
%    \Else
%      \While{$k \leq \hat{k}$}
%
%      \If {$y(k) < L_{\mathrm{low}}\ or \ y(k) > L_{\mathrm{upp}}$}
%  
%        \State \textbf{return} Verification Failed
%        
%      \EndIf
%  
%    \State increment $k$
%  
%    \EndWhile
%    \State \textbf{return} Verification Successful
%    \EndIf
%  \EndIf
%  
%  \If {$t_{\mathrm{sr}}<\hat{k} \times T_{\mathrm{s}}$}
%    \State \textbf{return} Verification Failed
%    \Else
%    \State \textbf{return} Verification Successful
%  \EndIf
%\EndProcedure
%\end{algorithmic}
%\end{algorithm}

\begin{algorithm}[H]
  \renewcommand{\algorithmcfname}{Algorítmo}%
  \SetAlgoLined
  \eSe{$y_\mathrm{p} \subset \Pi$}{
     $\hat{k} \gets k_\mathrm{r}$\;
  }{
  $k \gets \frac{t_{\mathrm{sr}}}{T_{\mathrm{s}}}$\;
  \eSe{$k > \hat{k}$}{
     $\hat{k} \gets k_\mathrm{r}$\;
  }{
  \Eq{$k \leq \hat{k}$}{
    \Se{$y(k) < L_{\mathrm{low}}\ or \ y(k) > L_{\mathrm{upp}}$}{
      Verification Failed\;
    }
    increment $k$\;
  }
  }
  }
  \eSe{$t_{\mathrm{sr}}<\hat{k} \times T_{\mathrm{s}}$}{
     Verification Failed\;
  }{
    Verification Successful\;
  }
  \caption{Verify Settling Time}\label{alg:settlingtime}
\end{algorithm}


\subsection{Verification Example}
\label{subsec:under_examp}

In order to provide a deeper understanding about the algorithms for overshoot and settling-time verification, we give a practical example, as follows. Starting with the proposed methodology for overshoot verification, we have to define a system and then analyze it, according to our approach:

\begin{equation}
\label{eq:discsystemcomplete3}
\Omega:\begin{cases}
x(k+1)=\begin{bmatrix}
1.5 & 1.0 & 0.0 \\
0.0 & 1.5 & 1.0 \\
0.0 & 0.0 & 1.5 
\end{bmatrix}x(k)+\begin{bmatrix}
-0.4 \\
2.5 \\
-0.8 
\end{bmatrix}u(k)\\
y(k)=\begin{bmatrix}
0.0 & 2.6 & 0.0 
\end{bmatrix}x(k)+[0]u(k)\\
u(k)=r(k)-Kx(k)
\end{cases},
\end{equation}
%
\noindent \text{where} $r(k)=u_{\mathrm{-1}}$ \text{is the unit step}. 

This way, \texttt{Step 1} is ready and \texttt{Step 2} is then considered, where a controller matrix $K$ is not defined, due to open-loop operation. Consequently, an FWL implementation (\texttt{Step 3}) is not provided either. Next, the desired requirements are defined, such as $PO_{\mathrm{r}}=9$, in \texttt{Step 4}, using a specification file \texttt{SpecsFile.ss}.

Given that open-loop was considered, this system is evaluated with ``\texttt{dsverifier SpecsFile.ss --property OVERSHOOT}'' and, as a consequence, ``\texttt{Verification FAILED}'' is returned, because the evaluated system is unstable and, consequently, there is no overshoot. One may notice that the proposed method always checks whether a system is stable.

As the chosen system is unstable, we can go back to \texttt{Step 2} and design a controller, in order to stabilize it and satisfy the required percentage overshoot ($PO_{\mathrm{r}}$), by using Lyapunov design~\cite{chen1995linear}. In that case, we use a controller matrix $K = [-0.7351~-5.0045~-18.5371]$ in \texttt{SpecsFile.ss}. Next, we run this experiment again, but now with option ``\texttt{--closed-loop}'' and still without FWL effects (\texttt{--no-fwl}), which results in \texttt{Verification SUCCESSFUL}, since DSVerifier returned $PO=2.6228$ that is less than $PO_{\mathrm{r}}=9$. 

Finally, this experiment can consider FWL effects. That is accomplished by using format $\langle 4,4 \rangle$, controller matrix $K_{\mathrm{FWL}} = [-0.6875 ~-5.0~-18.5]$, and omitting \texttt{--no-fwl} (\texttt{Step A}), which results in ``\texttt{Verification FAILED}'', due to the fact that the system is still unstable. In order to evaluate other formats, $\langle 8,8 \rangle $ and $\langle 16,16 \rangle$ were considered, in \texttt{Step 2}. As a consequence, $\langle 8,8 \rangle $ ($K_{\mathrm{FWL}} = [-0.7344~-5.0039~-18.5352]$) resulted in ``\texttt{Verification SUCCESSFUL}'', given that DSVerifier returned $PO=1.6153$, which is lower than $PO_{\mathrm{r}}=9$, and $\langle 16,16 \rangle$ ($K_{\mathrm{FWL}} = [-0.7351~-5.0045~-18.5370]$) also resulted in ``\texttt{Verification SUCCESSFUL}'', because our methodology provided $PO=2.6253$, which is again lower than the required value. 


Now, we analyze our settling-time verification approach, by following the steps in Figure~\ref{fig:diag1}. This way, \texttt{Step 1} is ready and \texttt{Step 2} is then considered, where a controller matrix $K$ is not defined, due to open-loop operation. Consequently, an FWL implementation (\texttt{Step 3}) is not provided either. Next, the desired requirements are defined, that is, $t_{\mathrm{sr}}=10s$, $p=5$, and $T_{\mathrm{s}}=0.5s$, in \texttt{Step 4}, using a specification file \texttt{SpecsFile.ss}.

Finally, given that open-loop operation was considered, this system is evaluated with ``\texttt{dsverifier SpecsFile.ss --property SETTLING\_TIME}''. \texttt{Steps A} to \texttt{E} of the proposed methodology are automatically performed by DSVerifier, considering an open-loop implementation, and, as a consequence, `` \texttt{Verification FAILED}'' is returned, because the evaluated system is unstable, since its eigenvalues are greater than $1$ ($\lambda=1.5$, due to Eq. \eqref{lamb}). One may notice that the proposed method first checks whether a system is stable, between \texttt{Steps A} and \texttt{B}.

As the chosen system is unstable, we can go back to \texttt{Step 2} and design a controller, in order to stabilize it and satisfy the required settling time, by using Lyapunov design~\cite{chen1995linear}. In that case, we use the same controller matrix $K = [-0.7351~-5.0045~-18.5371]$ in \texttt{SpecsFile.ss}, as  explained in Section~\ref{subsec:overshootAlg}. Since that controller was designed to satisfy both properties (settling-time and overshoot), this experiment is run again, but now with option ``\texttt{--closed-loop}'' and still without FWL effects (\texttt{--no-fwl}), which results in ``\texttt{Verification SUCCESSFUL}'', as can be seen in Figure~\ref{fig:stmethod}(a), where the step response does not leave the settling-time region between $k_{sr}$ and $\hat{k}$.

Finally, this experiment can consider FWL effects. That is accomplished by using format $\langle 4,4 \rangle$, controller matrix $K_{FWL} = [-0.6875 ~-5.0~-18.5]$, and omitting \texttt{--no-fwl} (\texttt{Step A}), which results in ``\texttt{Verification FAILED}'', as shown in Figure~\ref{fig:stmethod}(b), where the system becomes unstable. It is worth noticing that controller matrix $K$ in \texttt{SpecsFile.ss} is not modified and $K_{\mathrm{FWL}}$ is internally computed by DSVerifier.

In order to evaluate other formats, $\langle 8,8 \rangle $ and $\langle 16,16 \rangle$ are considered in \texttt{Step 2}. As a consequence, $K_{\mathrm{FWL}} = [-0.7344~-5.0039~-18.5352]$ with ``\texttt{Verification FAILED}'', because the step response left the settling-time region between $k_{\mathrm{sr}}$ and $\hat{k}$, and $K_{\mathrm{FWL}} = [-0.7351~-5.0045~-18.5370]$ with ``\texttt{Verification SUCCESSFUL}'', because the step response did not leave the settling-time region between $k_{\mathrm{sr}}$ and $\hat{k}$, are respectively obtained, as can be seen in Figures~\ref{fig:stmethod}(c) and (d). 

\begin{figure}[ht]
   \centering
   \subfloat[][]{\includegraphics[trim={0.4cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl.eps}}\quad
   \subfloat[][]{\includegraphics[trim={2cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl8b.eps}}\\
   \subfloat[][]{\includegraphics[trim={0.5cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl16b.eps}}\quad
   \subfloat[][]{\includegraphics[trim={0.5cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl32b.eps}}
   \caption{Settling-time verification for the example system, (a) without FWL effects and with formats (b) $\langle 4,4 \rangle$, (c) $\langle 8,8 \rangle$, and (d) $\langle 16,16 \rangle$.
   }
   \label{fig:stmethod}
\end{figure}

The number of bits heavily influence settling-times in real implementations, due to FWL effects. In addition, ``\texttt{Verification FAILED}'' was obtained for an intermediate format $\langle 8,8 \rangle $, while it was successful with $\langle 16,16 \rangle $. Indeed, given that the resulting settling-time is mostly dependent on the fastest natural response and its damping ratio \cite{boyd1991linear}, the interaction between them after quantization may cause such a behavior, which further reinforces the use of the proposed methodology, during design phases.

One may also notice that the properties tackled during design phases are also modified, due to changes in coefficients and computation results. In particular, overshoot was affected in different ways, which means that if a property fails, the other may not, as can be seen for format $\langle 8,8 \rangle $.


One may notice that $t_{\mathrm{sr}}=10s$ is the sample $n=20$, discretized at $T_{\mathrm{s}}=0.5s$. Figure~\ref{fig:stmethod}(a) shows that $k_{\mathrm{sr}}=t_{\mathrm{sr}}/T_{\mathrm{s}}=20$ is less than the calculated $\hat{k}=37$ (Eq.~\ref{eq:kbar}) and, as a consequence, for this required settling-time, the system is already in the settling time region, so that settling-time is doable in that case. Finally, the same reasoning is valid for Figures~\ref{fig:stmethod}(b), (c) and (d), where we can analyze responses and check them according to Algorithm~\ref{alg:settlingtime}.

%-------------------------------------------------------------------
\section{Synthesis of Non-fragile Performance Specification Requirements}
\label{sec:synthesis}
%-------------------------------------------------------------------

In this section, we show our proposed synthesis methodology based on performance specification requirements for digital control systems. In particular, we analyze settling-time and maximum overshoot specifications, for digital state-feedback control systems. The proposed synthesis approach, which employs our verification methodologies for settling-time and overshoot, as explained in Sections~\ref{subsec:overshootAlg} and \ref{subsec:settime-alg}, is based on the CEGIS synthesis technique, where there are two stages: verification and learning (where the synthesizer is located) as we can see in Figure~\ref{fig:cegisDiag}. In the learning stage, we generate a controller $K$ in order to satisfy our required parameter (settling-time and/or overshoot), using genetic algorithms~\cite{deb2004introduction}, where we take the system's definitions and the requirements as constraints. After generating the controller $K$, there is the verification stage where it gets the controller $K$ and verifies if meets the requirements, according to our verification methodologies, and if it fails in that stage, it goes back to learning stage and keep work in that loop, until it get success in the verification or the synthesizer reaches a maximum number of attempts.

In Figure~\ref{fig:SynthArch}, we show the proposed synthesis architecture in a general form, where system definitions represent the system as a whole (state-space matrices, inputs, etc), requirements are the requirements to be synthesized, \texttt{total\_attempts} is the total number of attempts of synthesize a controller, \texttt{attempts} represents the number of attempts without change any synthesis parameter (genetic algorithm), GA is the block that performs the generation of a candidate controller though genetic algorithm (GA), \texttt{verify()} is the verification engine (Sections~\ref{subsec:overshootAlg} and \ref{subsec:settime-alg}) which rely on what we are synthesizing (settling-time and/or overshoot), \texttt{MAXATT} is the maximum number of attempts to synthesize a controller (informed by the user), \texttt{MAXINNERATT} represents the maximum number of attempts without change any GA parameter, \texttt{popsize} is the population size of the genetic algorithm and \texttt{STEP} is the step to increment the GA population.

\begin{figure}[ht]
\begin{center}
\includegraphics[trim={0.0cm 0.0cm 0.0cm 0cm}, clip,width=0.35\textwidth]{figures/FlowchartArch.eps}
\caption{Proposed synthesis architecture.} 
\label{fig:SynthArch}
\end{center}
\end{figure}

Our proposed synthesis methodology works as follows. We first define the system to be synthesized (plant, inputs, etc) and the requirements to be met (settling-time/overshoot), and then we choose what we want meet in the synthesis process. Additionaly, we run the genetic algorithm using the required constraints (settling-time and/or overshoot), so we generate a candidate controller $K$. Now, we perform the verification process (according to the property we chose to synthesize); if the verification has success, the synthesis is successfuly and it finishes the process. Otherwise the verification fails and we check if the total number of attempts exceeded the maximum number of attempts, if yes, the synthesis process fails and it finishes, contrarily, we check if the number of attempts without change any GA parameter exceeded the maximum number defined for that, if no it goes back to run the GA again (and continues the process again), on the other hand, we increment the population size of the GA, by a step fixed, and after that we re-execute the GA and continue the process again.

%\begin{tikzpicture}[node distance=1cm]
%\node (start) [startstop] {Start};
%\node (in1) [io, below of=start,align=left] {total\_attempts = 0 \\ inner\_attempts = 0};
%\node (proc1) [process, below of=in1] {GA};
%\node (proc2) [io, below of=proc1,align=left] {total\_attempts++ \\ inner\_attempts++};
%\node (dec1) [decision, below of=proc2, yshift=-0.5cm] {Verify};
%\node (dec2) [decision, below of=dec1, yshift=-0.5cm] {total\_attempts > MAX};
%\node (dec3) [decision, below of=dec2, yshift=-0.5cm] {inner\_attempts > MAX2};
%\node (proc3) [process, below of=dec3] {popsize \+\= steppop \\ inner\_attempts = 0};
%%\node (proc2a) [process, below of=dec1, yshift=-0.5cm] {Process 2a};
%%\node (proc2b) [process, below of=dec1, xshift=3cm, yshift=2.3cm] {Process 2b};
%\node (out1) [io, below of=dec1] {Output};
%\node (stop) [startstop, below of=out1] {Stop};
%\draw [arrow] (start) -- (in1);
%\draw [arrow] (in1) -- (proc1);
%\draw [arrow] (proc1) -- (proc2);
%\draw [arrow] (proc2) -- (dec1);
%\draw [arrow] (dec1) -- node[anchor=east] {yes} (out1);
%\draw [arrow] (dec1) -- node[anchor=south] {no} (dec2);
%\draw [arrow] (dec2) -| node[anchor=east] {yes} (out1);
%\draw [arrow] (dec2) -- node[anchor=east] {no} (dec3);
%\draw [arrow] (dec3) -- node[anchor=south] {yes} (proc3);
%\draw [arrow] (dec3) |- node[anchor=west] {yes} (proc1);
%\draw [arrow] (proc3) -- node[anchor=west] {} (proc1);
%\draw [arrow] (out1) -- (stop);
%
%
%
%\end{tikzpicture}



%--------------------------------------------------------------
\subsection{Generating candidate controller $K$}
\label{subsec:genK}
%--------------------------------------------------------------

In our CEGIS synthesis methodology, we use genetic algorithms to generate a candidate controller $K$, in order to satisfy the desired requirements (overshoot and settling-time). Our methodology uses a multi-objective functions to solve three separated problems: synthesize for overshoot, settling-time or both. The multi-objective functions are:
\begin{equation}
	\label{eq:objfuncSumK}
	\begin{array}{ccc}
		\mathbf{f}_\mathrm{1}(K)=K \times K^T\\
	\end{array}
\end{equation}

\noindent and

\begin{equation}
	\label{eq:objfuncST}
	\begin{array}{ccc}
		\mathbf{f}_\mathrm{2}(K)=\hat{k}\\
	\end{array}
\end{equation}

\noindent where $K$ is the controller matrix and $\hat{k}$ is given by Eq.~\ref{eq:kbar}.

\subsubsection{Optimization problem for overshoot}
\label{ssubsec:genKover}
With the goal of generating a controller matrix $K$ through genetic algorithms, in order to satisfy overshoot requirements, we have used the following problem formulation.

The optimization problem consists in minimizing $\mathbf{f}_\mathrm{1}$ and $\mathbf{f}_\mathrm{2}$ with respect to the decision variable $K$. Thus, the optimization problem is represented as follows:
%
\begin{equation}
	\label{eq:optproblemOS}
	\begin{array}{ccc}
		\min & (\mathbf{f}_\mathrm{1}(K),\mathbf{f}_\mathrm{2}(K)),  \\
  \\
		\textrm{ s.t. } & PO \leq PO_{\mathrm{r}}, \\
                        & \bar{\lambda} \leq 1      
 \\
	\end{array}
\end{equation}

The first constraint means that the actual percentage overshoot must be smaller than the required percentage overshoot ($PO_{r}$. The second constraint is related to system's stability, where $\bar{\lambda}$ is the maximum absolute value among the system's eigenvalues (Section~\ref{sec:modformver}) and this value must be smaller than $1$, otherwise, the system is unstable.

\subsubsection{Optimization problem for settling-time}
\label{ssubsec:genKst}

We formulate an optimization problem to generate $K$ in order to satisfies settling-time requirements.

The optimization problem consists in minimizing $\mathbf{f}_\mathrm{1}$ and $\mathbf{f}_\mathrm{2}$ with respect to the decision variable $K$. Thus, the optimization problem is represented as follows:
%
\begin{equation}
	\label{eq:optproblemST}
	\begin{array}{ccc}
		\min & (\mathbf{f}_\mathrm{1}(K),\mathbf{f}_\mathrm{2}(K)),  \\
  \\
		\textrm{ s.t. } & {\hat{k}} \leq k_{\mathrm{sr}}, \\
                        & \bar{\lambda} \leq 1
 \\
	\end{array}
\end{equation}

In this optimization problem, the first constraint means that $\hat{k}$ must be smaller than the required settling-time in discrete-time ($k_{sr}$, because as we can see in Algorithm~\ref{alg:settlingtime}, when that happens the verification is successful which mean that the system meets the required settling-time. The second constraint is related to system's stability, where $\bar{\lambda}$ is the maximum absolute value among the system's eigenvalues (Section~\ref{sec:modformver}) and this value must be smaller than $1$, otherwise, the system is unstable.

\subsubsection{Optimization problem to meet overshoot and settling-time}
\label{ssubsec:genKovst}

In order to generate a controller $K$ using genetic algorithm that satisfies both overshoot and settling-time requirements, we formulate the following optimization problem.

\begin{equation}
	\label{eq:optproblemOVST}
	\begin{array}{ccc}
		\min & (\mathbf{f}_\mathrm{1}(K),\mathbf{f}_\mathrm{2}(K)),  \\
  \\
		\textrm{ s.t. } & {\hat{k}} \leq k_{\mathrm{sr}}, \\
                        & PO \leq PO_{\mathrm{r}}, \\
                        & \bar{\lambda} \leq 1
 \\
	\end{array}
\end{equation}

In this case, we want no minimize hte multi-objective functions ($\mathbf{f}_\mathrm{1}$ and $\mathbf{f}_\mathrm{2}$) constrained to: $\hat{k} \leq k_\mathrm{sr}$, $PO \leq PO_{\mathrm{r}}$ and $\bar{\lambda} \leq 1$. The first constraint garantee that the system meets the settling-time requirement, since $ k_\mathrm{sr} \geq \hat{k}$ (cf. Algorithm~\ref{alg:settlingtime}). The second constraint assure the maximum percentage overshoot required (cf. Algorithm~\ref{alg:overshootReal}).  Finally, the third constraint ensure that controller $K$ will keep the system stable, in consideration of $\bar{\lambda}$ being the largest absolute eigenvalue and that being smaller than $1$ provides stability.

\section{Resumo}\label{chap-4-summary}

Neste capítulo foi apresesentado o método proposto para localizar falhas em programas concorrentes usando técnicas de verificação de modelos e sequencialização, sendo esta a contribuição maior do presente trabalho. Foi dada uma explicação detalhada das transformações necessárias, assim como um exemplo para ilustrar melhor o processo de localização de falhas. Mostrou-se também a importância do contraexemplo obtido antes da aplicação do método proposto, visto que o mesmo contém a ordem das {\it threads} executadas e os pontos onde trocas de contexto ocorreram. A modelagem necessária para transformar declarações de programa concorrentes em sequenciais também foi explicada, assim como a estrutura fixa necessária para reproduzir a mesma ordem de execução do programa original. Por fim, um método sequencial pode ser aplicado no novo código para obter as linhas que levam às falhas do programa. Como resultado, tem-se o embasamento para a avaliação experimental realizada no próximo capítulo.
