\chapter{A Metodologia Proposta}\label{chap_methodology}

Neste capítulo, a metodologia proposta para sintetizar controlodores digitais com realimentação de estados, considerando fragilidade e especificações de desempenho será completamente descrita. Primeiramente, mostraremos as metodologias formalizadas para verificar sistemas de controle digital, com respeito a especificações de performance, no caso máximo tempo de assentamento e máximo sobressinal. A formalização utilizada para estimar o máximo sobressinal, bem como a invariante formalizada para verificar o máximo tempo de assentamento. Também são descritos os algoritmos criados para fazer a devida verificação das mesmas. Finalmente, a descrição completa da técnica que utilizamos para realizar o processo de síntese.

\section{Visão Geral do Método}
\label{sec:method-overview}

Aqui, o método proposto é descrito brevemente, como mostrado na Figura~\ref{figure:methodology}, e uma explicação mais detalhada é exposta nas seções seguitnes. Dado um programa concorrente $P$, primeiramente checa-se se ele apresenta uma execução mal-sucedida com relação a uma determinada intercalação. Para realizar tal tarefa, $P$ é executado em um verificador de modelos duas vezes: a primeira execução verifica se existe algum bloqueio fatal e a segunda é responsável por outros tipos de violação, tais como erros de aquisição de semáforo, divisão por zero, segurança de ponteiros, estouro aritmético e violação de limites de vetores. Não é possível verificá-lo apenas uma vez porque os verificadores de modelos separam essas verificações, \textit{i.e.}, é necessário adicionar uma opção de linha de comando para habilitar a detecção de bloqueios fatais e ignorar violações devido a assertivas. Caso um contraexemplo possa ser obtido nesse passo, é possível prosseguir com o método. Então, o próximo passo define as regras de transformação, que são as instruções sequenciais que substituirão as originais concorrentes, e um arcabouço sequencial, o qual tem como objetivo simular a execução concorrente da intercalação mal-sucedida. O terceiro passo consiste em usar o método proposto por Griesmayer~\cite{Griesmayer:2007} para instrumentar atribuições e expressões, de forma a apontar locais e instruções defeituosas do programa. Tal programa instrumentado pode então ser executado, usando um verificador de modelos, e é possível coletar as linhas defeituosas, até que a verificação associada não produza diferentes elementos. Essa iteração é descrita na Figura~\ref{figure:methodology} por meio dos passos $3$, $4$, já que o método busca novos contraexemplos, com o intuito de encontrar novas linhas defeituosas. Finalmente, as linhas defeituosas são obtidas, assim como atribuições necessárias para produzir uma execução bem-sucedida de $P$.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/methodology}
  \caption{Metodologia proposta.}
  \label{figure:methodology}
\end{figure}

%-------------------------------------------------------------------
\section{Verifying Non-fragile Performance Specification Requirements}
\label{sec:verification}
%-------------------------------------------------------------------

Neste trabalho utilizamos uma variação da síntese do CEGIS para sintetizar um controlador digital, a fim de satisfazer os requmáximo sobressinal. Na estratégia do CEGIS, temos basicamente duas etapas principais: síntese e verificação. Nesta seção, mostramos o método de verificação do tempo de assentamento e do máximo sobressinal dos sistemas de controle digital.
%--------------------------------------------------------------------------------
\subsection{Estimativa do Máximo Sobressinal}
\label{sec:modformver}
%--------------------------------------------------------------------------------

Algoritmo~\ref{alg:overshootEst} descreve um procedimento para estimar $y_{\mathrm{p}}$ (valor máximo de pico na resposta de um sistema) e $k_{\mathrm{p}}$ (amostra onde $y_{\mathrm{p}}$ está localizado), a fim de encontrar uma abordagem formal para verificar o máximo sobressinal usado em nossa abordagem CEGIS.

\begin{algorithm}[H]
\footnotesize
  \renewcommand{\algorithmcfname}{Algoritmo}%
  \SetAlgoLined
  %\KwPr{}
  $y_\mathrm{p} \gets y(k)$\;
  $lastGrad \gets 1$\;
  \While{verdadeiro}{
  \eIf{$|y(k+1)|>|y(k)|$}{
     $gradient = (gradient>0)?(gradient+1):1$\;
     \If{$|y(k+1)| != |y(k)|$}{
      $firstGradSample = y(k+1)$\;
      $firstGradSampleIdx = k+1$\;
    }
  }{
    $gradient = (gradient<0)?(gradient-1):-1$\;
  }
  \If{$(lastGrad>0) ~and~ (gradient < 0)$}{
     \uIf{$|firstGradSample| <= |k_\mathrm{p}|$}{
       increment $numBadPeaks$\;
       \eIf{$numBadPeaks > 2$}{
         $exit(\textbf{loop})$\;
       }{
         $y_\mathrm{p} = firstGradSample$\;
         $k_\mathrm{p} = firstGradSampleIdx$\;
       }
     }\uElseIf{$(grad > 10) ~and~ (|(y(k+1)-yss)/yss| < 0.001)$}{
       \eIf{$|yss|>|y_\mathrm{p}|$}{
         $y_\mathrm{p} = yss$\;
         $k_\mathrm{p} = 0$\;
       }{
         $exit(\textbf{loop})$\;
       }
     }
  }
  $lastGrad = grad$\;
  increment $k$\;
  }
  \caption{\texttt{estimate\_maxPeak\_value} - Estimation of $y_{\mathrm{p}}$ and $k_{\mathrm{p}}$}\label{alg:overshootEst}
\end{algorithm}

The procedure basically looks for the maximum peak value in the output response of a system, using the concept of gradient to check if there is a peak. We start at the first sample of the output system, and compare the next samples, and then we proceed to find the largest peak (with the same sign of $y_\mathrm{ss}$) which is our maximum peak value $y_\mathrm{p}$.

O procedimento basicamente procura o valor de pico máximo na resposta da saída de um sistema, usando o conceito de gradiente para verificar se há um pico. Começamos na primeira amostra do sistema de saída e comparamos as amostras subsequentes, e então continuamos a encontrar o maior pico (com o mesmo sinal de $y_mathrm{ss}$) que é o nosso valor máximo de pico $y_\mathrm{p}$.


%--------------------------------------------------------------------------------
\subsection{Estimação da Invariante de Máximo Tempo de Assentamento}
\label{sec:modformver}
%--------------------------------------------------------------------------------

Neste trabalho, desejamos verificar se um determinado sistema de controle digital atende a um tempo de assentamento requerido e, como consequência, precisamos modelar seu comportamento. Além disso, usamos $\hat{k}$ como uma invariante para a verificação de tempo de assentamento. Um mapeamento $\phi$ de uma dada coleção $M$ de objetos matemáticos dotados de uma relação de equivalência fixa $\rho$, em outra coleção $N$ de objetos matemáticos, que é constante nas classes de equivalência de $M$, com relação a $\rho$ (mais precisamente, isso é uma invariante da relação de equivalência $\rho$ em $M$). Se $X$ é um objeto em $M$, então pode-se dizer que $\phi(M)$ é uma invariante do objeto $X$~\cite{springer2006invariant}. Em outras palavras, uma vez que calculamos $\hat{k}$, ele permanecerá inalterado.

Nesse sentido, dado que $S_\mathrm{1}=\{|\lambda_{\mathrm{1}},|\lambda_{\mathrm{2}},\dots,|\lambda_n|\}$ seja o conjunto de valores absolutos de autovalores~\cite{chen1995linear} do sistema $\Omega$ e $\overline{\lambda} = \max(S_{\mathrm{1}})$. Podemos agora definir uma função heurística que representa a resposta de saída de $\bar{\Omega}$ como

\begin{equation}\label{eq:saidaNova}
\overline{y}(k)=y_{\mathrm{ss}}+\overline{c}\overline{\lambda}^{k}~,
\end{equation}

\noindent where $\overline{c}$ is a constant that makes $\overline{y}(k)$ enter the settling-time region. Indeed, the heuristic function above uses the slowest eigenvalue $\bar{\lambda}$, ensuring that $\bar{\Omega}$ always reaches the settling-time region after $\Omega$.

In summary, we can find a heuristic function based on the largest eigenvalue of $\Omega$ and then check the moment it enters a settling-time region, because if that happens before the required settling-time, that is also true for $\Omega$.

In order to verify the settling-time of a system, we indicate a settling-time region as a percentage $p$, usually between $0\%$ and $5\%$~\cite{dorf2011modern}, so its upper and lower limits are,

\noindent onde $\overline{c}$ é uma constante que faz $\overline{y}(k)$ entrar na região de assentamento $\Pi$. Na verdade, a função heurística acima usa o autovalor mais ´´lento'' $\bar{\lambda}$, garantindo que $\bar{\Omega}$ sempre alcance a região assentamento após $\Omega$.

Em resumo, podemos encontrar uma função heurística baseada no maior autovalor de $ Omega$, em termos de magnitude, e então verificar o momento em que ela entra em uma região assentamento porque se isso acontecer antes do tempo de assentamento requerido, isso também é válido para $\Omega$.

Para verificar o tempo de assentamento de um sistema, indicamos uma região de assentamento como uma porcentagem $ p $, geralmente entre $ 0 \% $ e $ 5 \% $~\cite{dorf2011modern}, portanto seus limites superior e inferior são,

\begin{equation}\label{eq:lupp}
L_{\mathrm{upp}}=\left(1+\frac{p}{100}\right) y_{\mathrm{ss}}
\end{equation}

\noindent and
\begin{equation}
L_{\mathrm{low}}=\left(1-\frac{p}{100}\right) y_{\mathrm{ss}},
\end{equation}

\noindent respectivamente. O instante ($\hat{k}$) quando um sistema entra em sua região de assentamento pode ser encontrado simplesmente fazendo com que Eq.~\eqref{eq:saidaNova} seja igual a Eq.~\eqref{eq:lupp} , devido à forma da curva na Eq.~\eqref{eq:saidaNova}, como segue:

\begin{center}
\begin{equation*}
\begin{aligned}
\left( 1+\frac{p}{100}\right) y_{\mathrm{ss}}=y_{\mathrm{ss}}+\overline{c}\overline{\lambda}^{\hat{k}}\\
y_{\mathrm{ss}}+\frac{p}{100}y_{\mathrm{ss}}=y_{\mathrm{ss}}+\overline{c}\overline{\lambda}^{\hat{k}} \\
\overline{c}\overline{\lambda}^{\hat{k}}=\frac{p}{100}y_{\mathrm{ss}} \\
\log_{\overline{\lambda}} \overline{\lambda}^{\hat{k}}=\log_{\overline{\lambda}}\left( \frac{p}{100\overline{c}}y_{\mathrm{ss}}\right)
\end{aligned}
\end{equation*}

\begin{equation}\label{eq:kbar}
\begin{aligned}
{\hat{k}}=\ceil{  \log_{\overline{\lambda}}\left( \frac{p}{100\overline{c}}y_{\mathrm{ss}}\right)}.
\end{aligned}
\end{equation}
\end{center}

O maior pico da saída do sistema, $y_\mathrm{p}$, pode ser obtido para calcular $\overline{c}$ e, como consequência, com Eq.~\eqref{eq:saidaNova}, fazemos

\begin{equation}\label{eq:cbar}
\begin{aligned}
y_{\mathrm{p}}=&~y_{\mathrm{ss}}+\bar{c}{\bar{\lambda}}^{k_{\mathrm{p}}} \\
\bar{c}=&~\frac{y_{\mathrm{p}}-y_{\mathrm{ss}}}{{\bar{\lambda}}^{k_{\mathrm{p}}}}.
\end{aligned}
\end{equation}

\noindent $y_\mathrm{p}$ pode ser obtido, verificando a saída do sistema para encontrar o maior valor em magnitude com o mesmo sinal de $y_\mathrm{ss}$ e $k_\mathrm{p}$ é a amostra em que $y_\mathrm{p}$ está localizado.

\subsection{Algoritmo de Verificação de Sobressinal}
\label{subsec:overshootAlg}

Nesta seção, explicamos nossa técnica de verificação de máximo sobressinal, que consiste em verificar se o percentual exigido de sobressinal é menor ou igual ao percentual de sobressinal real (calculado).

O máximo sobressinal ($M_{\mathrm{p}}$) é o valor máximo transitório que excede $y_{\mathrm{ss}}$. A fim de encontrar a porcentagem de sobressinal, nós executamos a seguinte computação:

\begin{equation}
\begin{aligned}
M_{\mathrm{p}} =&~ y_{\mathrm{p}}-y_{\mathrm{ss}} \\
PO =&~ 100\times\frac{M_{\mathrm{p}}}{y_{\mathrm{ss}}},
\end{aligned}
\label{eq:perc_overshoot}
\end{equation}
\noindent  onde $y_{\mathrm{p}}$ pode ser obtido do Algoritmo~\ref{alg:overshootEst}.

A Figura~\ref{fig:overshootDiag} mostra a metodologia de verificação de sobressinal proposta, que foi implementada no DSVerifier. Em primeiro lugar, o modelo de um sistema de controle (\texttt{Step 1}) é determinado e, em seguida, um controlador é projetado em malha fechada (\texttt{Step 2}). Depois disso, a implementação de FWL (\texttt{Step 3}) e o máximo sobressinal requerido para ser verificado (\texttt{Step 4}) são definidos, os quais são então usados para criar o arquivo \texttt{SpecsFile.ss}. Em seguida, a estabilidade do sistema é verificada e, se for estável, a especificação do máximo sobressinal é avaliada.
  
\begin{figure}[H]
\begin{center}
\includegraphics[trim={0.0cm 0.0cm 0.0cm 0cm}, clip,width=0.5\textwidth]{figures/ArchOverShooting.eps}
\caption{Overshoot verification.} 
\label{fig:overshootDiag}
\end{center}
\end{figure}

A verificação de máximo sobressinal consiste basicamente em verificar se a porcentagem de sobressinall computada $P.O.$ (Eq.~\ref{eq:perc_overshoot}) é menor do que o percentual de sobressinal requerido ($P.O._{\mathrm{r}}$). Se for esse o caso, ele retorna \texttt{Verification SUCCESSFUL}; caso contrário, \texttt{Verification FAILED} será exibido, conforme ilustrado no Algorithm~\ref{alg:overshootReal}.

%\begin{algorithm}[H]
%\caption{Verify Overshoot }
%\label{alg:overshootReal}
%\begin{algorithmic}[1]
%\Procedure{checkOvershoot($y_{\mathrm{ss}}$, $PO_{\mathrm{r}}$)}{}
%
%    \State $y_{\mathrm{p}} \gets estimate\_maxPeak\_value() $
%    \State $PO \gets \frac{y_{\mathrm{p}}-y_{\mathrm{ss}}}{y_{\mathrm{ss}}}$
%
%    \If {$PO > PO_{\mathrm{r}}$}
%  
%      \State \textbf{return} Verification Failed
%        
%    \EndIf
%
%\State \textbf{return} Verification Successful
%
%\EndProcedure
%\end{algorithmic}
%\end{algorithm}

\begin{algorithm}[H]
  \renewcommand{\algorithmcfname}{Algoritmo}%
  \SetAlgoLined
%  \KwPr{}
  \KwData{$y_{\mathrm{ss}}$, $PO_{\mathrm{r}}$}
%  \KwRes{how to write algorithm with \LaTeX2e }
  $y_{\mathrm{p}} \gets estimate\_maxPeak\_value() $\;
  $PO \gets \frac{y_{\mathrm{p}}-y_{\mathrm{ss}}}{y_{\mathrm{ss}}}$\;
  \eSe{$PO > PO_{\mathrm{r}}$}{
     Verification Failed\;
  }{
  Verification Successful\;
  }
  \caption{Verify Overshoot}\label{alg:overshootReal}
\end{algorithm}


\subsection{Algoritmo de Verificação de Tempo de Assentamento}
\label{subsec:settime-alg}

Nesta seção, mostramos nosso algoritmo para verificação de tempo de assentamento, onde usamos o invariante $\hat{k}$ (veja a seção \ref{sec:modformver}). Nossa metodologia, que é ilustrada na Figura\ref{fig:diag1}, fornece verificação de tempo de assentamento em sistemas em malha aberta e fechada; no entanto, os primeiros não apresentam controladores e, consequentemente, os efeitos de FWL não são levados em conta. A primeira etapa consiste em obter os parâmetros de entrada necessários, matrizes de espaço de estados $ A $, $ B $, $ C $ e $ D $ e uma entrada do sistema $ u $, que é seguida por um controlador digital, se um sistema em malha fechada for considerado (\texttt{Step 2}). Então, o tempo de assentamento requerido $t_{\mathrm{sr}}$, a porcentagem $ p $ da região de assentamento e o tempo de amostragem $T_\mathrm{s}$ são definidos (\texttt{Step 4 }), que é seguido por uma implementação de FWL, quando em malha fechada (\texttt{Step 3}). Depois disso, os passos \texttt{A} a \texttt{E} são executados, {\it i.e.}, cálculo do controlador com FWL, se for escolhido em malha fechada (\texttt{Step A}) e valor de estado estacionário ($y_{\mathrm{ss}}$), como descrito em Eq.~\eqref{eq:yss2} (\texttt{Step B}), estimativa dos maiores valores de pico da saída do sistema ($y_{\mathrm{p}}$) e a amostra $k_{\mathrm{p}}$ onde $y_{\mathrm{p}} $ está localizado (\texttt{Step C}) e, finalmente, computação de $\overline{\lambda}$ (\texttt{Step D}), $\overline{c}$ e $\hat{k}$ (\texttt{Step E}).

%\begin{algorithm}
%    \caption{Procedure to find the instant $k_\mathrm{r}$}
%    \label{alg:kreach}
%    \begin{algorithmic}[1] % The number tells where the line numbering should start
%        \Procedure{}{}
%          \While {$y(k) \not\subset \Pi$}
%            \State increment $k$
%          \EndWhile
%          \State $k_\mathrm{r} \gets k$
%        \EndProcedure
%    \end{algorithmic}
%\end{algorithm}

\begin{algorithm}[H]
  \renewcommand{\algorithmcfname}{Algoritmo}%
  \SetAlgoLined
  \Eq{$y(k) \not\subset \Pi$}{
    incrementar $k$\;
  }
  $k_\mathrm{r} \gets k$\;
  \caption{Procedimento para encontrar o instante $k_\mathrm{r}$}\label{alg:kreach}
\end{algorithm}


\begin{figure*}[ht]
\begin{center}
\includegraphics[trim={0.0cm 0.0cm 0.0cm 0cm}, clip,width=0.7\textwidth]{figures/Archstever.eps}
\caption{The proposed settling-time verification methodology.} 
\label{fig:diag1}
\end{center}
\end{figure*}


The proposed procedure for verifying settling-times, which is described in Algorithm~\ref{alg:settlingtime}, consists in first checking if $\hat{k}$, which was previously computed and used as parameter, is lower than the required settling-time $k_{\mathrm{sr}}=\frac{t_{\mathrm{sr}}}{T_\mathrm{s}}$, which can also be checked through $\hat{k} \times T_{\mathrm{s}} \leq t_{\mathrm{sr}}$ (as used in Algorithm~\ref{alg:settlingtime}). If that is the case, we can assure that the output signal is within $\Pi$ (see Section \ref{sec:modformver}) after $t_{\mathrm{sr}}$ and, as a consequence, the associated verification is already successful; otherwise, we still need to check if $y$ remains within $\Pi$ from $k_{\mathrm{sr}}$ to $\hat{k}$ and, if the latter is not true for any sample $y$, the resulting verification fails.

O procedimento proposto para verificar os tempos de assentamento, que é descrito no Algoritmo~\ref{alg:settlingtime}, consiste em primeiro verificar se $\hat{k}$, que foi previamente calculado e usado como parâmetro, é menor que tempo de assentamento requerido $k_{\mathrm{sr}} = \frac{t_{\mathrm{sr}}} {T_\mathrm{s}}$, que também pode ser verificado através de $\hat{k} \times T_{\mathrm{s}} \leq t_{\mathrm{sr}}$ (como usado no Algorithm~\ref{alg:settlingtime}). Se este for o caso, podemos assegurar que o sinal de saída está dentro de $\Pi$ (veja Seção \ref{sec:modformver}) após $t_{\mathrm{sr}}$ e, como consequência, a verificação associada já é bem sucedido; caso contrário, ainda precisamos verificar se $y$ permanece dentro de $\Pi$ de $k_{\mathrm{sr}}$ a $\hat{k}$ e, se este último não for verdadeiro para qualquer amostra $y$, a verificação resultante falha.


%\begin{algorithm}[H]
%\caption{Verify Settling Time }
%\label{alg:settlingtime}
%\begin{algorithmic}[1]
%\Procedure{checkSettlingTime(%$\hat{k}$, $t_{\mathrm{sr}}$, $T_{\mathrm{s}}$, $L_{\mathrm{low}}$, $L_{\mathrm{upp}}$
%)}{}
%
%  \If {$y_\mathrm{p} \subset \Pi$}
%    \State {$\hat{k} \gets k_\mathrm{r}$}
%  %\EndIf
%  
%  \Else
%
%    \State $k \gets \frac{t_{\mathrm{sr}}}{T_{\mathrm{s}}}$
%    \If {$k > \hat{k}$}
%      \State \textbf{return} Verification Successful
%    \Else
%      \While{$k \leq \hat{k}$}
%
%      \If {$y(k) < L_{\mathrm{low}}\ or \ y(k) > L_{\mathrm{upp}}$}
%  
%        \State \textbf{return} Verification Failed
%        
%      \EndIf
%  
%    \State increment $k$
%  
%    \EndWhile
%    \State \textbf{return} Verification Successful
%    \EndIf
%  \EndIf
%  
%  \If {$t_{\mathrm{sr}}<\hat{k} \times T_{\mathrm{s}}$}
%    \State \textbf{return} Verification Failed
%    \Else
%    \State \textbf{return} Verification Successful
%  \EndIf
%\EndProcedure
%\end{algorithmic}
%\end{algorithm}

\begin{algorithm}[H]
  \renewcommand{\algorithmcfname}{Algoritmo}%
  \SetAlgoLined
  \eSe{$y_\mathrm{p} \subset \Pi$}{
     $\hat{k} \gets k_\mathrm{r}$\;
  }{
  $k \gets \frac{t_{\mathrm{sr}}}{T_{\mathrm{s}}}$\;
  \eSe{$k > \hat{k}$}{
     $\hat{k} \gets k_\mathrm{r}$\;
  }{
  \Eq{$k \leq \hat{k}$}{
    \Se{$y(k) < L_{\mathrm{low}}\ or \ y(k) > L_{\mathrm{upp}}$}{
      Verification Failed\;
    }
    increment $k$\;
  }
  }
  }
  \eSe{$t_{\mathrm{sr}}<\hat{k} \times T_{\mathrm{s}}$}{
     Verification Failed\;
  }{
    Verification Successful\;
  }
  \caption{Verify Settling Time}\label{alg:settlingtime}
\end{algorithm}


\subsection{Verification Example}
\label{subsec:under_examp}

A fim de fornecer uma compreensão mais profunda sobre os algoritmos de verificação de máximo sobressinal e tempo de assentamento, a seguir é apresentado um exemplo prático. Começando com a metodologia proposta para a verificação de máximo sobressinal, temos que definir um sistema e depois analisá-lo, de acordo com a nossa abordagem:


\begin{equation}
\label{eq:discsystemcomplete3}
\Omega:\begin{cases}
x(k+1)=\begin{bmatrix}
1.5 & 1.0 & 0.0 \\
0.0 & 1.5 & 1.0 \\
0.0 & 0.0 & 1.5 
\end{bmatrix}x(k)+\begin{bmatrix}
-0.4 \\
2.5 \\
-0.8 
\end{bmatrix}u(k)\\
y(k)=\begin{bmatrix}
0.0 & 2.6 & 0.0 
\end{bmatrix}x(k)+[0]u(k)\\
u(k)=r(k)-Kx(k)
\end{cases},
\end{equation}
%
\noindent onde $r(k)=u_{\mathrm{-1}}$ é o degrau unitário.

Desta forma, \texttt{Step 1} está pronto e \texttt{Step 2} é então considerado, onde uma matriz do controlador $K$ não está definida, devido à operação em malha aberta. Consequentemente, uma implementação de FWL (\texttt{Step 3}) também não é fornecida. Em seguida, os requisitos desejados são definidos, como $PO_{\mathrm{r}} = 9$, em \texttt{Step 4}, usando um arquivo de especificação \texttt{SpecsFile.ss}.

Dado que a operaço em malha aberta foi considerada, este sistema é avaliado com ``\texttt{dsverifier SpecsFile.ss - property OVERSHOOT}'' e, como consequência, ``\texttt{Verification FAILED}'' é retornado, porque o sistema avaliado é instável e, consequentemente, não há sobressinal. Pode-se notar que o método proposto sempre verifica se um sistema é estável.

Como o sistema escolhido é instável, podemos voltar para \texttt{Step 2} e projetar um controlador, a fim de estabilizá-lo e satisfazer o percentual de sobressinal requido ($PO_{\mathrm{r}}$), usando a técnica de Lyapunov~\cite{chen1995linear}. Nesse caso, usamos um controlador $K = [-0.7351 ~ -5.0045 ~ -18.5371]$ em \texttt{SpecsFile.ss}. Em seguida, executamos esse experimento novamente, mas agora com a opção ``\texttt{--closed-loop}'' e ainda sem efeitos FWL (\texttt{--no-fwl}), o que resulta em \texttt{Verification SUCCESSFUL}, desde que o DSVerifier retornou $PO = 2.6228$ que é menor que $PO_{\mathrm{r}} = 9$.

Finalmente, consideramos os efeitos de FWL nesse experimento. Isso é feito usando o formato $ \langle 4,4 \rangle $, a matriz do controlador $K_{\mathrm{FWL}} = [-0.6875 ~ -5.0 ~ -18.5] $ e omitindo \texttt{--no-fwl} (\texttt{Step A}), que resulta em ``\texttt{Verification FAILED}'', devido ao fato de o sistema ainda estar instável. Para avaliar outros formatos, $ \langle 8,8 \rangle $ e $ \langle 16,16 \rangle $ foram considerados, em \texttt{Step 2}. Como consequência, $ \langle 8,8 \rangle $ ($K_{\mathrm{FWL}} = [-0.7344 ~ -5,0039 ~ -18.5352] $) resultou em ``\texttt{Verification SUCCESSFUL}'', dado que o DSVerifier retornou $ PO = 1.6153 $, que é menor que $ PO_{\mathrm{r}} = 9 $ e $ \langle 16,16 \rangle $ ($ K_{\mathrm{FWL}} = [-0.7351 ~ -5.0045 ~ -18.5370] $) também resultou em ``\texttt{Verification SUCCESSFUL}'', porque nossa metodologia forneceu $ PO = 2.6253 $, que é novamente menor que o valor requerido.

Agora, analisamos nossa abordagem de verificação de tempo de assentamento, seguindo os passos da Figura~\ref{fig:diag1}. Desta forma, \texttt{Step 1} está pronto e \texttt{Step 2} é então considerado, onde uma matriz do controlador $ K $ não está definida, devido à operação em malha aberta. Consequentemente, uma implementação de FWL (\texttt{Step 3}) também não é fornecida. Em seguida, os requisitos desejados são definidos, ou seja, $ t_{\mathrm{sr}} = 10s $, $ p = 5 $ e $ T_{\mathrm{s}} = 0.5s $, em \texttt{Step 4}, usando um arquivo de especificação \texttt{SpecsFile.ss}.

Finalmente, considerando que a operação em malha aberta foi considerada, este sistema é avaliado com ``\texttt{dsverifier SpecsFile.ss - property SETTLING\_TIME}''. \texttt{Steps A} a \texttt{E} da metodologia proposta são automaticamente executados pelo DSVerifier, considerando uma implementação em malha aberta, e, como consequência, ``\texttt{Verification FAILED}'' é retornado, porque o sistema avaliado é instável, pois seus autovalores são maiores que $ 1 $ ($ \lambda = 1.5 $, devido à Eq.~\eqref{lamb}). Pode-se notar que o método proposto primeiro verifica se um sistema é estável, entre \texttt{Steps A} e \texttt{B}.

Como o sistema escolhido é instável, podemos voltar para o \texttt{Step 2} e projetar um controlador, a fim de estabilizá-lo e satisfazer o tempo de assentamento requerido, usando o Lyapunov~\cite{chen1995linear}. Nesse caso, usamos a mesma matriz do controlador $ K = [-0.7351 ~ -5.0045 ~ -18.5371] $ em \texttt{SpecsFile.ss}, como explicado em Seção~\ref{subsec:overshootAlg}. Como esse controlador foi projetado para satisfazer ambas as propriedades (tempo de assentamento e sobressinal), esse experimento é executado novamente, mas agora com a opção ``\texttt{--closed-loop}'' e ainda sem efeitos FWL (\texttt{--no-fwl}), que resulta em ``\texttt{Verification SUCCESSFUL}'', como pode ser visto na Figura~\ref{fig:stmethod}(a), onde a resposta ao degrau não deixa a região de assentamento entre $ k_{\mathrm{sr}} $ e $ \hat{k}$.

Finalmente, esse experimento pode considerar os efeitos de FWL. Isso é feito usando o formato $ \langle 4,4 \rangle $, a matriz do controlador $ K_{\mathrm {FWL}} = [-0.6875 ~ -5.0 ~ -18.5] $ e omitindo \texttt{--no-fwl} (\texttt{Step A}), que resulta em ``\texttt{Verification FAILED}'', como mostrado na Figura~\ref{fig:stmethod}(b), onde o sistema se torna instável. Vale a pena notar que a matriz do controlador $ K $ em \texttt{SpecsFile.ss} não é modificada e $ K_{\mathrm {FWL}} $ é internamente calculado pelo DSVerifier.

In order to evaluate other formats, $\langle 8,8 \rangle $ and $\langle 16,16 \rangle$ are considered in \texttt{Step 2}. As a consequence, $K_{\mathrm{FWL}} = [-0.7344~-5.0039~-18.5352]$ with ``\texttt{Verification FAILED}'', because the step response left the settling-time region between $k_{\mathrm{sr}}$ and $\hat{k}$, and $K_{\mathrm{FWL}} = [-0.7351~-5.0045~-18.5370]$ with ``\texttt{Verification SUCCESSFUL}'', because the step response did not leave the settling-time region between $k_{\mathrm{sr}}$ and $\hat{k}$, are respectively obtained, as can be seen in Figures~\ref{fig:stmethod}(c) and (d).
Para avaliar outros formatos, $ \langle 8,8 \rangle $ e $ \langle 16,16 \rangle $ são considerados em \texttt{Step 2}. Como consequência, $ K_{\mathrm{FWL}} = [-0.7344 ~ -5.0039 ~ -18.5352] $ com ``\texttt{Verification FAILED}'', porque a resposta ao degrau deixou a região de assentamento entre $ k_{\mathrm{sr}} $ e $ \hat{k} $ e $ K_{\mathrm{FWL}} = [-0.7351 ~ -5.0045 ~ -18.5370] $ com ``\texttt{Verification SUCCESSFUL}'', porque a resposta ao degrau não deixou a região de assentamento entre $ k_{\mathrm{sr}} $ e $ \hat{k} $, são respectivamente obtidas, como pode ser visto nas Figuras~\ref{fig:stmethod} (c) e (d).


\begin{figure}[ht]
   \centering
   \subfloat[][]{\includegraphics[trim={0.4cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl.eps}}\quad
   \subfloat[][]{\includegraphics[trim={2cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl8b.eps}}\\
   \subfloat[][]{\includegraphics[trim={0.5cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl16b.eps}}\quad
   \subfloat[][]{\includegraphics[trim={0.5cm 0cm 3cm 0cm}, clip,width=.4\textwidth]{figures/exDM13cl32b.eps}}
   \caption{Settling-time verification for the example system, (a) without FWL effects and with formats (b) $\langle 4,4 \rangle$, (c) $\langle 8,8 \rangle$, and (d) $\langle 16,16 \rangle$.
   }
   \label{fig:stmethod}
\end{figure}

O número de bits influencia fortemente os tempos de assentamento em implementações reais, devido a efeitos de FWL. Além disso, ``\texttt{Verification FAILED}'' foi obtido para um formato intermediário $ \langle 8,8 \rangle $, enquanto foi bem sucedido com $ \langle 16,16 \rangle $. De fato, dado que o tempo de assentamento resultante é principalmente dependente da resposta natural mais rápida e sua taxa de amortecimento, a interação entre eles após a quantificação pode causar tal comportamento, o que reforça ainda mais o uso da metodologia proposta, durante fases de projeto.

Pode-se notar também que as propriedades abordadas durante as fases de projeto também são modificadas, devido a mudanças nos coeficientes e nos resultados de cálculo. Em particular, o sobressinal foi afetado de maneiras diferentes, o que significa que, se uma propriedade falhar, a outra talvez não falhe, como pode ser visto no formato $ \langle 8,8 \rangle $.

One may notice that $t_{\mathrm{sr}}=10s$ is the sample $n=20$, discretized at $T_{\mathrm{s}}=0.5s$. Figure~\ref{fig:stmethod}(a) shows that $k_{\mathrm{sr}}=t_{\mathrm{sr}}/T_{\mathrm{s}}=20$ is less than the calculated $\hat{k}=37$ (Eq.~\ref{eq:kbar}) and, as a consequence, for this required settling-time, the system is already in the settling time region, so that settling-time is doable in that case. Finally, the same reasoning is valid for Figures~\ref{fig:stmethod}(b), (c) and (d), where we can analyze responses and check them according to Algorithm~\ref{alg:settlingtime}.
Pode-se notar que $ t_{\mathrm{sr}} = 10s $ é a amostra $ n = 20 $, discretizada em $ T_{\mathrm{s}} = 0.5s $. A Figura~\ref{fig:stmethod} (a) mostra que $ k_{\mathrm{sr}} = t_{\mathrm{sr}} / T_{\mathrm{s}} = 20 $ é menor que o $\hat{k} = 37 $ calculado (Eq.~\ref{eq:kbar}) e, como consequência, para este tempo de assentamento requerido, o sistema já está na região de assentamento, para que o tempo de assentamento seja possível nesse caso. Finalmente, o mesmo raciocínio é válido para as Figuras~\ref{fig:stmethod} (b), (c) e (d), onde podemos analisar as respostas e verificá-las de acordo com o Algoritmo~\ref{alg:settlingtime}.


%-------------------------------------------------------------------
\section{Synthesis of Non-fragile Performance Specification Requirements}
\label{sec:synthesis}
%-------------------------------------------------------------------

In this section, we show our proposed synthesis methodology based on performance specification requirements for digital control systems. In particular, we analyze settling-time and maximum overshoot specifications, for digital state-feedback control systems. The proposed synthesis approach, which employs our verification methodologies for settling-time and overshoot, as explained in Sections~\ref{subsec:overshootAlg} and \ref{subsec:settime-alg}, is based on the CEGIS synthesis technique, where there are two stages: verification and learning (where the synthesizer is located) as we can see in Figure~\ref{fig:cegisDiag}. In the learning stage, we generate a controller $K$ in order to satisfy our required parameter (settling-time and/or overshoot), using genetic algorithms~\cite{deb2004introduction}, where we take the system's definitions and the requirements as constraints. After generating the controller $K$, there is the verification stage where it gets the controller $K$ and verifies if meets the requirements, according to our verification methodologies, and if it fails in that stage, it goes back to learning stage and keep work in that loop, until it get success in the verification or the synthesizer reaches a maximum number of attempts.

In Figure~\ref{fig:SynthArch}, we show the proposed synthesis architecture in a general form, where system definitions represent the system as a whole (state-space matrices, inputs, etc), requirements are the requirements to be synthesized, \texttt{total\_attempts} is the total number of attempts of synthesize a controller, \texttt{attempts} represents the number of attempts without change any synthesis parameter (genetic algorithm), GA is the block that performs the generation of a candidate controller though genetic algorithm (GA), \texttt{verify()} is the verification engine (Sections~\ref{subsec:overshootAlg} and \ref{subsec:settime-alg}) which rely on what we are synthesizing (settling-time and/or overshoot), \texttt{MAXATT} is the maximum number of attempts to synthesize a controller (informed by the user), \texttt{MAXINNERATT} represents the maximum number of attempts without change any GA parameter, \texttt{popsize} is the population size of the genetic algorithm and \texttt{STEP} is the step to increment the GA population.

\begin{figure}[ht]
\begin{center}
\includegraphics[trim={0.0cm 0.0cm 0.0cm 0cm}, clip,width=0.45\textwidth]{figures/FlowchartArch.eps}
\caption{Proposed synthesis architecture.} 
\label{fig:SynthArch}
\end{center}
\end{figure}

Our proposed synthesis methodology works as follows. We first define the system to be synthesized (plant, inputs, etc) and the requirements to be met (settling-time/overshoot), and then we choose what we want meet in the synthesis process. Additionaly, we run the genetic algorithm using the required constraints (settling-time and/or overshoot), so we generate a candidate controller $K$. Now, we perform the verification process (according to the property we chose to synthesize); if the verification has success, the synthesis is successfuly and it finishes the process. Otherwise the verification fails and we check if the total number of attempts exceeded the maximum number of attempts, if yes, the synthesis process fails and it finishes, contrarily, we check if the number of attempts without change any GA parameter exceeded the maximum number defined for that, if no it goes back to run the GA again (and continues the process again), on the other hand, we increment the population size of the GA, by a step fixed, and after that we re-execute the GA and continue the process again.

%\begin{tikzpicture}[node distance=1cm]
%\node (start) [startstop] {Start};
%\node (in1) [io, below of=start,align=left] {total\_attempts = 0 \\ inner\_attempts = 0};
%\node (proc1) [process, below of=in1] {GA};
%\node (proc2) [io, below of=proc1,align=left] {total\_attempts++ \\ inner\_attempts++};
%\node (dec1) [decision, below of=proc2, yshift=-0.5cm] {Verify};
%\node (dec2) [decision, below of=dec1, yshift=-0.5cm] {total\_attempts > MAX};
%\node (dec3) [decision, below of=dec2, yshift=-0.5cm] {inner\_attempts > MAX2};
%\node (proc3) [process, below of=dec3] {popsize \+\= steppop \\ inner\_attempts = 0};
%%\node (proc2a) [process, below of=dec1, yshift=-0.5cm] {Process 2a};
%%\node (proc2b) [process, below of=dec1, xshift=3cm, yshift=2.3cm] {Process 2b};
%\node (out1) [io, below of=dec1] {Output};
%\node (stop) [startstop, below of=out1] {Stop};
%\draw [arrow] (start) -- (in1);
%\draw [arrow] (in1) -- (proc1);
%\draw [arrow] (proc1) -- (proc2);
%\draw [arrow] (proc2) -- (dec1);
%\draw [arrow] (dec1) -- node[anchor=east] {yes} (out1);
%\draw [arrow] (dec1) -- node[anchor=south] {no} (dec2);
%\draw [arrow] (dec2) -| node[anchor=east] {yes} (out1);
%\draw [arrow] (dec2) -- node[anchor=east] {no} (dec3);
%\draw [arrow] (dec3) -- node[anchor=south] {yes} (proc3);
%\draw [arrow] (dec3) |- node[anchor=west] {yes} (proc1);
%\draw [arrow] (proc3) -- node[anchor=west] {} (proc1);
%\draw [arrow] (out1) -- (stop);
%
%
%
%\end{tikzpicture}



%--------------------------------------------------------------
\subsection{Generating candidate controller $K$}
\label{subsec:genK}
%--------------------------------------------------------------

In our CEGIS synthesis methodology, we use genetic algorithms to generate a candidate controller $K$, in order to satisfy the desired requirements (overshoot and settling-time). Our methodology uses a multi-objective functions to solve three separated problems: synthesize for overshoot, settling-time or both. The multi-objective functions are:
\begin{equation}
	\label{eq:objfuncSumK}
	\begin{array}{ccc}
		\mathbf{f}_\mathrm{1}(K)=K \times K^T\\
	\end{array}
\end{equation}

\noindent and

\begin{equation}
	\label{eq:objfuncST}
	\begin{array}{ccc}
		\mathbf{f}_\mathrm{2}(K)=\hat{k}\\
	\end{array}
\end{equation}

\noindent where $K$ is the controller matrix and $\hat{k}$ is given by Eq.~\ref{eq:kbar}.

\subsubsection{Optimization problem for overshoot}
\label{ssubsec:genKover}
With the goal of generating a controller matrix $K$ through genetic algorithms, in order to satisfy overshoot requirements, we have used the following problem formulation.

The optimization problem consists in minimizing $\mathbf{f}_\mathrm{1}$ and $\mathbf{f}_\mathrm{2}$ with respect to the decision variable $K$. Thus, the optimization problem is represented as follows:
%
\begin{equation}
	\label{eq:optproblemOS}
	\begin{array}{ccc}
		\min & (\mathbf{f}_\mathrm{1}(K),\mathbf{f}_\mathrm{2}(K)),  \\
  \\
		\textrm{ s.t. } & PO \leq PO_{\mathrm{r}}, \\
                        & \bar{\lambda} \leq 1      
 \\
	\end{array}
\end{equation}

The first constraint means that the actual percentage overshoot must be smaller than the required percentage overshoot ($PO_{r}$. The second constraint is related to system's stability, where $\bar{\lambda}$ is the maximum absolute value among the system's eigenvalues (Section~\ref{sec:modformver}) and this value must be smaller than $1$, otherwise, the system is unstable.

\subsubsection{Optimization problem for settling-time}
\label{ssubsec:genKst}

We formulate an optimization problem to generate $K$ in order to satisfies settling-time requirements.

The optimization problem consists in minimizing $\mathbf{f}_\mathrm{1}$ and $\mathbf{f}_\mathrm{2}$ with respect to the decision variable $K$. Thus, the optimization problem is represented as follows:
%
\begin{equation}
	\label{eq:optproblemST}
	\begin{array}{ccc}
		\min & (\mathbf{f}_\mathrm{1}(K),\mathbf{f}_\mathrm{2}(K)),  \\
  \\
		\textrm{ s.t. } & {\hat{k}} \leq k_{\mathrm{sr}}, \\
                        & \bar{\lambda} \leq 1
 \\
	\end{array}
\end{equation}

In this optimization problem, the first constraint means that $\hat{k}$ must be smaller than the required settling-time in discrete-time ($k_{sr}$, because as we can see in Algorithm~\ref{alg:settlingtime}, when that happens the verification is successful which mean that the system meets the required settling-time. The second constraint is related to system's stability, where $\bar{\lambda}$ is the maximum absolute value among the system's eigenvalues (Section~\ref{sec:modformver}) and this value must be smaller than $1$, otherwise, the system is unstable.

\subsubsection{Optimization problem to meet overshoot and settling-time}
\label{ssubsec:genKovst}

In order to generate a controller $K$ using genetic algorithm that satisfies both overshoot and settling-time requirements, we formulate the following optimization problem.

\begin{equation}
	\label{eq:optproblemOVST}
	\begin{array}{ccc}
		\min & (\mathbf{f}_\mathrm{1}(K),\mathbf{f}_\mathrm{2}(K)),  \\
  \\
		\textrm{ s.t. } & {\hat{k}} \leq k_{\mathrm{sr}}, \\
                        & PO \leq PO_{\mathrm{r}}, \\
                        & \bar{\lambda} \leq 1
 \\
	\end{array}
\end{equation}

In this case, we want no minimize hte multi-objective functions ($\mathbf{f}_\mathrm{1}$ and $\mathbf{f}_\mathrm{2}$) constrained to: $\hat{k} \leq k_\mathrm{sr}$, $PO \leq PO_{\mathrm{r}}$ and $\bar{\lambda} \leq 1$. The first constraint garantee that the system meets the settling-time requirement, since $ k_\mathrm{sr} \geq \hat{k}$ (cf. Algorithm~\ref{alg:settlingtime}). The second constraint assure the maximum percentage overshoot required (cf. Algorithm~\ref{alg:overshootReal}).  Finally, the third constraint ensure that controller $K$ will keep the system stable, in consideration of $\bar{\lambda}$ being the largest absolute eigenvalue and that being smaller than $1$ provides stability.

\section{Resumo}\label{chap-4-summary}

Neste capítulo foi apresesentado o método proposto para localizar falhas em programas concorrentes usando técnicas de verificação de modelos e sequencialização, sendo esta a contribuição maior do presente trabalho. Foi dada uma explicação detalhada das transformações necessárias, assim como um exemplo para ilustrar melhor o processo de localização de falhas. Mostrou-se também a importância do contraexemplo obtido antes da aplicação do método proposto, visto que o mesmo contém a ordem das {\it threads} executadas e os pontos onde trocas de contexto ocorreram. A modelagem necessária para transformar declarações de programa concorrentes em sequenciais também foi explicada, assim como a estrutura fixa necessária para reproduzir a mesma ordem de execução do programa original. Por fim, um método sequencial pode ser aplicado no novo código para obter as linhas que levam às falhas do programa. Como resultado, tem-se o embasamento para a avaliação experimental realizada no próximo capítulo.
